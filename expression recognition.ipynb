{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-02T07:32:29.053917Z",
     "iopub.status.busy": "2020-09-02T07:32:29.053280Z",
     "iopub.status.idle": "2020-09-02T07:32:29.059619Z",
     "shell.execute_reply": "2020-09-02T07:32:29.060088Z"
    },
    "papermill": {
     "duration": 0.022399,
     "end_time": "2020-09-02T07:32:29.060226",
     "exception": false,
     "start_time": "2020-09-02T07:32:29.037827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/fer2013/fer2013.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T07:32:29.083469Z",
     "iopub.status.busy": "2020-09-02T07:32:29.082711Z",
     "iopub.status.idle": "2020-09-02T07:32:29.085586Z",
     "shell.execute_reply": "2020-09-02T07:32:29.085129Z"
    },
    "papermill": {
     "duration": 0.015522,
     "end_time": "2020-09-02T07:32:29.085699",
     "exception": false,
     "start_time": "2020-09-02T07:32:29.070177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-02T07:32:29.110971Z",
     "iopub.status.busy": "2020-09-02T07:32:29.110347Z",
     "iopub.status.idle": "2020-09-02T07:32:31.787415Z",
     "shell.execute_reply": "2020-09-02T07:32:31.786846Z"
    },
    "papermill": {
     "duration": 2.692086,
     "end_time": "2020-09-02T07:32:31.787523",
     "exception": false,
     "start_time": "2020-09-02T07:32:29.095437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/fer2013/fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T07:32:31.822440Z",
     "iopub.status.busy": "2020-09-02T07:32:31.815339Z",
     "iopub.status.idle": "2020-09-02T07:32:31.831263Z",
     "shell.execute_reply": "2020-09-02T07:32:31.831741Z"
    },
    "papermill": {
     "duration": 0.033281,
     "end_time": "2020-09-02T07:32:31.831858",
     "exception": false,
     "start_time": "2020-09-02T07:32:31.798577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>6</td>\n",
       "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35883</th>\n",
       "      <td>3</td>\n",
       "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>0</td>\n",
       "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>3</td>\n",
       "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>2</td>\n",
       "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35887 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                             pixels        Usage\n",
       "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n",
       "1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n",
       "2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n",
       "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n",
       "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n",
       "...        ...                                                ...          ...\n",
       "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
       "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
       "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
       "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
       "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n",
       "\n",
       "[35887 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T07:32:31.864572Z",
     "iopub.status.busy": "2020-09-02T07:32:31.863865Z",
     "iopub.status.idle": "2020-09-02T07:33:17.465902Z",
     "shell.execute_reply": "2020-09-02T07:33:17.466725Z"
    },
    "papermill": {
     "duration": 45.624899,
     "end_time": "2020-09-02T07:33:17.466928",
     "exception": false,
     "start_time": "2020-09-02T07:32:31.842029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48, 1)\n",
      "(28709, 7)\n",
      "(3589, 48, 48, 1)\n",
      "(3589, 7)\n",
      "(3589, 48, 48, 1)\n",
      "(3589, 7)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "#加载csv文件，将数据和标签分离\n",
    "\n",
    "def load_fer(csv_file,mode):\n",
    "    content = pd.read_csv('../input/fer2013/fer2013.csv')\n",
    "    data = content[content['Usage'] == mode]\n",
    "    pixels = data['pixels'].tolist()#将像素转换为列表\n",
    "    width,height = 48,48#图像的宽和高\n",
    "    faces = [] #存放每张图像的像素信息\n",
    "    for pixel_seq in pixels:\n",
    "        face = [int(pixel) for pixel in pixel_seq.split()]\n",
    "        face = np.array(face) #转换为数组\n",
    "        face = face.reshape(width,height) #调整图像维度\n",
    "        face = cv2.resize(face.astype('uint8'),(48,48))\n",
    "        faces.append(face.astype('float32'))\n",
    "    faces = np.asarray(faces)\n",
    "    faces = np.expand_dims(faces,-1) #增加最后的通道维度\n",
    "    emotions = pd.get_dummies(data['emotion']).values\n",
    "    return faces,emotions\n",
    "face_train,emotion_train = load_fer('../input/fer2013/fer2013.csv','Training')\n",
    "face_val,emotion_val = load_fer('../input/fer2013/fer2013.csv','PublicTest')\n",
    "face_test,emotion_test = load_fer('../input/fer2013/fer2013.csv','PrivateTest')\n",
    "print(face_train.shape)\n",
    "print(emotion_train.shape)\n",
    "print(face_val.shape)\n",
    "print(emotion_val.shape)\n",
    "print(face_test.shape)\n",
    "print(emotion_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T07:33:17.497776Z",
     "iopub.status.busy": "2020-09-02T07:33:17.497122Z",
     "iopub.status.idle": "2020-09-02T07:33:23.414531Z",
     "shell.execute_reply": "2020-09-02T07:33:23.413962Z"
    },
    "papermill": {
     "duration": 5.935107,
     "end_time": "2020-09-02T07:33:23.414668",
     "exception": false,
     "start_time": "2020-09-02T07:33:17.479561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size = 32\n",
    "#增强数据，扩充数据集的大小\n",
    "data_gen = ImageDataGenerator(\n",
    "    featurewise_center = False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=.1,\n",
    "    horizontal_flip=True)\n",
    "train_gen = data_gen.flow(face_train, emotion_train, batch_size)\n",
    "val_gen = data_gen.flow(face_val, emotion_val, batch_size)\n",
    "test_gen = data_gen.flow(face_test,emotion_test, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T07:33:23.443777Z",
     "iopub.status.busy": "2020-09-02T07:33:23.443059Z",
     "iopub.status.idle": "2020-09-02T07:33:23.451520Z",
     "shell.execute_reply": "2020-09-02T07:33:23.451037Z"
    },
    "papermill": {
     "duration": 0.024476,
     "end_time": "2020-09-02T07:33:23.451616",
     "exception": false,
     "start_time": "2020-09-02T07:33:23.427140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898\n",
      "113\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "print(len(train_gen))\n",
    "print(len(val_gen))\n",
    "print(len(test_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T07:33:23.483857Z",
     "iopub.status.busy": "2020-09-02T07:33:23.482380Z",
     "iopub.status.idle": "2020-09-02T07:33:23.484973Z",
     "shell.execute_reply": "2020-09-02T07:33:23.485437Z"
    },
    "papermill": {
     "duration": 0.022574,
     "end_time": "2020-09-02T07:33:23.485542",
     "exception": false,
     "start_time": "2020-09-02T07:33:23.462968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T07:33:23.537162Z",
     "iopub.status.busy": "2020-09-02T07:33:23.521413Z",
     "iopub.status.idle": "2020-09-02T07:33:23.543572Z",
     "shell.execute_reply": "2020-09-02T07:33:23.544066Z"
    },
    "papermill": {
     "duration": 0.047209,
     "end_time": "2020-09-02T07:33:23.544175",
     "exception": false,
     "start_time": "2020-09-02T07:33:23.496966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n",
    "    #首先对数据进行正则化，可以避免数据集出现过拟合的现象\n",
    "    '''数据预处理：\n",
    "    1、归一化：将训练集中某一列数值特征的值缩放到0-1之间,当目标受多个不同维度的特征制约时，例如影响房子价格的因素包括：房子的面积、房子的年代等，数值相差比较大时，归一到同一区间\n",
    "        [Xi-min(Xi)]/[max(Xi)-min(Xi)]\n",
    "    2、标准化：将训练集中某一列的特征缩放成均值为0，方差为1的状态，标准化后数据范围不一定是0-1之间，数据分布不会改变\n",
    "        [Xi-x(均值)]/sd(x)\n",
    "        在PCA、聚类、逻辑回归、支持向量机、神经网络中常用到标准化\n",
    "    归一化、标准化都是对某个特征进行缩放而不是对某个样本的特征向量进行缩放\n",
    "    目的：提高模型的精度、提升收敛的速度\n",
    "    3、正则化：当需要保持数据的原始量纲的情况下，不能对数据进行标准化或者归一化处理\n",
    "    正则化主要用来防止过拟合，对于损失函数添加上正则项，求约束函数和正则化项之和的最小值'''\n",
    "    regularization = l2(l2_regularization)\n",
    "\n",
    "    # base\n",
    "    img_input = Input(input_shape)\n",
    "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "                                            use_bias=False)(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "                                            use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # module 1\n",
    "    residual = Conv2D(16, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "    #先对通道进行卷积减小维度，再对空间进行卷积，最终输出16通道的特征图\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 2\n",
    "    residual = Conv2D(32, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 3\n",
    "    residual = Conv2D(64, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 4\n",
    "    residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    x = Conv2D(num_classes, (3, 3),\n",
    "            #kernel_regularizer=regularization,\n",
    "            padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Activation('softmax',name='predictions')(x)\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T07:33:23.571509Z",
     "iopub.status.busy": "2020-09-02T07:33:23.570818Z",
     "iopub.status.idle": "2020-09-02T07:33:23.573418Z",
     "shell.execute_reply": "2020-09-02T07:33:23.573876Z"
    },
    "papermill": {
     "duration": 0.018048,
     "end_time": "2020-09-02T07:33:23.573989",
     "exception": false,
     "start_time": "2020-09-02T07:33:23.555941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T07:33:23.608071Z",
     "iopub.status.busy": "2020-09-02T07:33:23.607452Z",
     "iopub.status.idle": "2020-09-02T08:11:38.251487Z",
     "shell.execute_reply": "2020-09-02T08:11:38.252518Z"
    },
    "papermill": {
     "duration": 2294.666921,
     "end_time": "2020-09-02T08:11:38.252752",
     "exception": false,
     "start_time": "2020-09-02T07:33:23.585831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 46, 46, 8)    72          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 46, 46, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 46, 46, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 44, 44, 8)    576         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 44, 44, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 44, 44, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d (SeparableConv (None, 44, 44, 16)   200         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 44, 44, 16)   64          separable_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 44, 44, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 44, 44, 16)   400         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 44, 44, 16)   64          separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 22, 22, 16)   128         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 22, 22, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 22, 22, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 22, 22, 16)   0           max_pooling2d[0][0]              \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 22, 22, 32)   656         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 22, 22, 32)   128         separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 22, 22, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 22, 22, 32)   1312        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 22, 22, 32)   128         separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 11, 11, 32)   512         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 11, 11, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 11, 11, 32)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 11, 11, 64)   2336        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 11, 11, 64)   256         separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 11, 11, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 11, 11, 64)   4672        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 6, 6, 64)     2048        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 6, 6, 64)     256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 6, 6, 64)     0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 6, 6, 128)    8768        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 6, 6, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 6, 6, 128)    17536       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 3, 3, 128)    8192        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 3, 3, 128)    512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 3, 3, 128)    0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 3, 3, 7)      8071        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 7)            0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 1.7866 - accuracy: 0.3197\n",
      "Epoch 00001: val_loss improved from inf to 1.83040, saving model to models/_mini_XCEPTION.01-accuracy0.32.hdf5\n",
      "898/897 [==============================] - 21s 23ms/step - loss: 1.7860 - accuracy: 0.3200 - val_loss: 1.8304 - val_accuracy: 0.3720\n",
      "Epoch 2/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 1.5070 - accuracy: 0.4361\n",
      "Epoch 00002: val_loss improved from 1.83040 to 1.47694, saving model to models/_mini_XCEPTION.02-accuracy0.44.hdf5\n",
      "898/897 [==============================] - 19s 21ms/step - loss: 1.5066 - accuracy: 0.4362 - val_loss: 1.4769 - val_accuracy: 0.4572\n",
      "Epoch 3/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 1.3830 - accuracy: 0.4844\n",
      "Epoch 00003: val_loss improved from 1.47694 to 1.36330, saving model to models/_mini_XCEPTION.03-accuracy0.48.hdf5\n",
      "898/897 [==============================] - 20s 22ms/step - loss: 1.3825 - accuracy: 0.4847 - val_loss: 1.3633 - val_accuracy: 0.4831\n",
      "Epoch 4/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 1.3186 - accuracy: 0.5081\n",
      "Epoch 00004: val_loss did not improve from 1.36330\n",
      "898/897 [==============================] - 20s 22ms/step - loss: 1.3188 - accuracy: 0.5081 - val_loss: 1.3742 - val_accuracy: 0.4831\n",
      "Epoch 5/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 1.2761 - accuracy: 0.5238\n",
      "Epoch 00005: val_loss did not improve from 1.36330\n",
      "898/897 [==============================] - 20s 22ms/step - loss: 1.2760 - accuracy: 0.5238 - val_loss: 1.3974 - val_accuracy: 0.4879\n",
      "Epoch 6/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 1.2381 - accuracy: 0.5382\n",
      "Epoch 00006: val_loss did not improve from 1.36330\n",
      "898/897 [==============================] - 20s 23ms/step - loss: 1.2383 - accuracy: 0.5382 - val_loss: 1.3695 - val_accuracy: 0.5004\n",
      "Epoch 7/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 1.2167 - accuracy: 0.5419\n",
      "Epoch 00007: val_loss improved from 1.36330 to 1.31143, saving model to models/_mini_XCEPTION.07-accuracy0.54.hdf5\n",
      "898/897 [==============================] - 20s 23ms/step - loss: 1.2166 - accuracy: 0.5419 - val_loss: 1.3114 - val_accuracy: 0.5102\n",
      "Epoch 8/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 1.1906 - accuracy: 0.5522\n",
      "Epoch 00008: val_loss improved from 1.31143 to 1.30370, saving model to models/_mini_XCEPTION.08-accuracy0.55.hdf5\n",
      "898/897 [==============================] - 20s 22ms/step - loss: 1.1906 - accuracy: 0.5522 - val_loss: 1.3037 - val_accuracy: 0.5233\n",
      "Epoch 9/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 1.1787 - accuracy: 0.5611\n",
      "Epoch 00009: val_loss improved from 1.30370 to 1.17351, saving model to models/_mini_XCEPTION.09-accuracy0.56.hdf5\n",
      "898/897 [==============================] - 20s 22ms/step - loss: 1.1787 - accuracy: 0.5611 - val_loss: 1.1735 - val_accuracy: 0.5676\n",
      "Epoch 10/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 1.1577 - accuracy: 0.5664\n",
      "Epoch 00010: val_loss did not improve from 1.17351\n",
      "898/897 [==============================] - 20s 22ms/step - loss: 1.1577 - accuracy: 0.5664 - val_loss: 1.1846 - val_accuracy: 0.5639\n",
      "Epoch 11/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 1.1461 - accuracy: 0.5727\n",
      "Epoch 00011: val_loss did not improve from 1.17351\n",
      "898/897 [==============================] - 20s 23ms/step - loss: 1.1465 - accuracy: 0.5724 - val_loss: 1.2479 - val_accuracy: 0.5358\n",
      "Epoch 12/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 1.1337 - accuracy: 0.5757\n",
      "Epoch 00012: val_loss did not improve from 1.17351\n",
      "898/897 [==============================] - 19s 22ms/step - loss: 1.1342 - accuracy: 0.5755 - val_loss: 1.3686 - val_accuracy: 0.5169\n",
      "Epoch 13/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 1.1183 - accuracy: 0.5830\n",
      "Epoch 00013: val_loss did not improve from 1.17351\n",
      "898/897 [==============================] - 45s 50ms/step - loss: 1.1185 - accuracy: 0.5830 - val_loss: 1.2569 - val_accuracy: 0.5414\n",
      "Epoch 14/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 1.1072 - accuracy: 0.5877\n",
      "Epoch 00014: val_loss did not improve from 1.17351\n",
      "898/897 [==============================] - 21s 23ms/step - loss: 1.1071 - accuracy: 0.5878 - val_loss: 1.2268 - val_accuracy: 0.5564\n",
      "Epoch 15/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 1.0955 - accuracy: 0.5919\n",
      "Epoch 00015: val_loss improved from 1.17351 to 1.15773, saving model to models/_mini_XCEPTION.15-accuracy0.59.hdf5\n",
      "898/897 [==============================] - 21s 23ms/step - loss: 1.0955 - accuracy: 0.5919 - val_loss: 1.1577 - val_accuracy: 0.5829\n",
      "Epoch 16/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 1.0863 - accuracy: 0.5941\n",
      "Epoch 00016: val_loss did not improve from 1.15773\n",
      "898/897 [==============================] - 19s 21ms/step - loss: 1.0863 - accuracy: 0.5941 - val_loss: 1.3003 - val_accuracy: 0.5344\n",
      "Epoch 17/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 1.0777 - accuracy: 0.5963\n",
      "Epoch 00017: val_loss did not improve from 1.15773\n",
      "898/897 [==============================] - 21s 23ms/step - loss: 1.0777 - accuracy: 0.5963 - val_loss: 1.2477 - val_accuracy: 0.5400\n",
      "Epoch 18/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 1.0779 - accuracy: 0.5956\n",
      "Epoch 00018: val_loss did not improve from 1.15773\n",
      "898/897 [==============================] - 21s 23ms/step - loss: 1.0781 - accuracy: 0.5955 - val_loss: 1.2187 - val_accuracy: 0.5561\n",
      "Epoch 19/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 1.0682 - accuracy: 0.6037\n",
      "Epoch 00019: val_loss improved from 1.15773 to 1.13084, saving model to models/_mini_XCEPTION.19-accuracy0.60.hdf5\n",
      "898/897 [==============================] - 20s 22ms/step - loss: 1.0679 - accuracy: 0.6038 - val_loss: 1.1308 - val_accuracy: 0.5826\n",
      "Epoch 20/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 1.0621 - accuracy: 0.6065\n",
      "Epoch 00020: val_loss did not improve from 1.13084\n",
      "898/897 [==============================] - 21s 23ms/step - loss: 1.0622 - accuracy: 0.6065 - val_loss: 1.1437 - val_accuracy: 0.5787\n",
      "Epoch 21/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 1.0545 - accuracy: 0.6077\n",
      "Epoch 00021: val_loss improved from 1.13084 to 1.12905, saving model to models/_mini_XCEPTION.21-accuracy0.61.hdf5\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.0545 - accuracy: 0.6077 - val_loss: 1.1290 - val_accuracy: 0.5890\n",
      "Epoch 22/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 1.0504 - accuracy: 0.6093\n",
      "Epoch 00022: val_loss improved from 1.12905 to 1.11756, saving model to models/_mini_XCEPTION.22-accuracy0.61.hdf5\n",
      "898/897 [==============================] - 20s 22ms/step - loss: 1.0504 - accuracy: 0.6093 - val_loss: 1.1176 - val_accuracy: 0.5910\n",
      "Epoch 23/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 1.0436 - accuracy: 0.6127\n",
      "Epoch 00023: val_loss did not improve from 1.11756\n",
      "898/897 [==============================] - 20s 22ms/step - loss: 1.0436 - accuracy: 0.6127 - val_loss: 1.2811 - val_accuracy: 0.5389\n",
      "Epoch 24/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 1.0383 - accuracy: 0.6117\n",
      "Epoch 00024: val_loss did not improve from 1.11756\n",
      "898/897 [==============================] - 21s 24ms/step - loss: 1.0383 - accuracy: 0.6117 - val_loss: 1.2200 - val_accuracy: 0.5386\n",
      "Epoch 25/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 1.0375 - accuracy: 0.6127\n",
      "Epoch 00025: val_loss improved from 1.11756 to 1.11750, saving model to models/_mini_XCEPTION.25-accuracy0.61.hdf5\n",
      "898/897 [==============================] - 20s 22ms/step - loss: 1.0375 - accuracy: 0.6127 - val_loss: 1.1175 - val_accuracy: 0.5968\n",
      "Epoch 26/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 1.0254 - accuracy: 0.6187\n",
      "Epoch 00026: val_loss did not improve from 1.11750\n",
      "898/897 [==============================] - 21s 23ms/step - loss: 1.0254 - accuracy: 0.6187 - val_loss: 1.1763 - val_accuracy: 0.5754\n",
      "Epoch 27/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 1.0234 - accuracy: 0.6187\n",
      "Epoch 00027: val_loss did not improve from 1.11750\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.0233 - accuracy: 0.6186 - val_loss: 1.1669 - val_accuracy: 0.5740\n",
      "Epoch 28/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 1.0218 - accuracy: 0.6187\n",
      "Epoch 00028: val_loss did not improve from 1.11750\n",
      "898/897 [==============================] - 20s 22ms/step - loss: 1.0217 - accuracy: 0.6187 - val_loss: 1.1407 - val_accuracy: 0.5851\n",
      "Epoch 29/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 1.0214 - accuracy: 0.6170\n",
      "Epoch 00029: val_loss improved from 1.11750 to 1.08580, saving model to models/_mini_XCEPTION.29-accuracy0.62.hdf5\n",
      "898/897 [==============================] - 21s 24ms/step - loss: 1.0210 - accuracy: 0.6171 - val_loss: 1.0858 - val_accuracy: 0.6108\n",
      "Epoch 30/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 1.0114 - accuracy: 0.6238\n",
      "Epoch 00030: val_loss did not improve from 1.08580\n",
      "898/897 [==============================] - 20s 22ms/step - loss: 1.0114 - accuracy: 0.6238 - val_loss: 1.1204 - val_accuracy: 0.5890\n",
      "Epoch 31/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 1.0052 - accuracy: 0.6253\n",
      "Epoch 00031: val_loss did not improve from 1.08580\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 1.0053 - accuracy: 0.6252 - val_loss: 1.2367 - val_accuracy: 0.5545\n",
      "Epoch 32/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 1.0055 - accuracy: 0.6246\n",
      "Epoch 00032: val_loss improved from 1.08580 to 1.07945, saving model to models/_mini_XCEPTION.32-accuracy0.62.hdf5\n",
      "898/897 [==============================] - 20s 23ms/step - loss: 1.0052 - accuracy: 0.6248 - val_loss: 1.0794 - val_accuracy: 0.6035\n",
      "Epoch 33/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9989 - accuracy: 0.6268\n",
      "Epoch 00033: val_loss did not improve from 1.07945\n",
      "898/897 [==============================] - 20s 22ms/step - loss: 0.9991 - accuracy: 0.6267 - val_loss: 1.0915 - val_accuracy: 0.6116\n",
      "Epoch 34/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9951 - accuracy: 0.6282\n",
      "Epoch 00034: val_loss did not improve from 1.07945\n",
      "898/897 [==============================] - 23s 25ms/step - loss: 0.9948 - accuracy: 0.6283 - val_loss: 1.1258 - val_accuracy: 0.5960\n",
      "Epoch 35/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9926 - accuracy: 0.6303\n",
      "Epoch 00035: val_loss did not improve from 1.07945\n",
      "898/897 [==============================] - 21s 23ms/step - loss: 0.9928 - accuracy: 0.6302 - val_loss: 1.1329 - val_accuracy: 0.5874\n",
      "Epoch 36/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9870 - accuracy: 0.6308\n",
      "Epoch 00036: val_loss did not improve from 1.07945\n",
      "898/897 [==============================] - 20s 23ms/step - loss: 0.9870 - accuracy: 0.6308 - val_loss: 1.0849 - val_accuracy: 0.5965\n",
      "Epoch 37/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9868 - accuracy: 0.6341\n",
      "Epoch 00037: val_loss improved from 1.07945 to 1.07630, saving model to models/_mini_XCEPTION.37-accuracy0.63.hdf5\n",
      "898/897 [==============================] - 25s 28ms/step - loss: 0.9868 - accuracy: 0.6340 - val_loss: 1.0763 - val_accuracy: 0.6088\n",
      "Epoch 38/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9813 - accuracy: 0.6361\n",
      "Epoch 00038: val_loss did not improve from 1.07630\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9811 - accuracy: 0.6361 - val_loss: 1.0897 - val_accuracy: 0.6091\n",
      "Epoch 39/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9797 - accuracy: 0.6390\n",
      "Epoch 00039: val_loss did not improve from 1.07630\n",
      "898/897 [==============================] - 21s 23ms/step - loss: 0.9801 - accuracy: 0.6388 - val_loss: 1.1711 - val_accuracy: 0.5720\n",
      "Epoch 40/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9751 - accuracy: 0.6374\n",
      "Epoch 00040: val_loss did not improve from 1.07630\n",
      "898/897 [==============================] - 26s 29ms/step - loss: 0.9751 - accuracy: 0.6374 - val_loss: 1.1456 - val_accuracy: 0.5834\n",
      "Epoch 41/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9719 - accuracy: 0.6357\n",
      "Epoch 00041: val_loss did not improve from 1.07630\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.9723 - accuracy: 0.6356 - val_loss: 1.0877 - val_accuracy: 0.6049\n",
      "Epoch 42/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9745 - accuracy: 0.6372\n",
      "Epoch 00042: val_loss did not improve from 1.07630\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9746 - accuracy: 0.6373 - val_loss: 1.2937 - val_accuracy: 0.5375\n",
      "Epoch 43/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9703 - accuracy: 0.6387\n",
      "Epoch 00043: val_loss did not improve from 1.07630\n",
      "898/897 [==============================] - 26s 29ms/step - loss: 0.9703 - accuracy: 0.6387 - val_loss: 1.1709 - val_accuracy: 0.5653\n",
      "Epoch 44/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9673 - accuracy: 0.6401\n",
      "Epoch 00044: val_loss improved from 1.07630 to 1.07149, saving model to models/_mini_XCEPTION.44-accuracy0.64.hdf5\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9676 - accuracy: 0.6400 - val_loss: 1.0715 - val_accuracy: 0.6180\n",
      "Epoch 45/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9651 - accuracy: 0.6394\n",
      "Epoch 00045: val_loss did not improve from 1.07149\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.9652 - accuracy: 0.6392 - val_loss: 1.0951 - val_accuracy: 0.6060\n",
      "Epoch 46/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9604 - accuracy: 0.6435\n",
      "Epoch 00046: val_loss improved from 1.07149 to 1.05790, saving model to models/_mini_XCEPTION.46-accuracy0.64.hdf5\n",
      "898/897 [==============================] - 26s 29ms/step - loss: 0.9604 - accuracy: 0.6435 - val_loss: 1.0579 - val_accuracy: 0.6108\n",
      "Epoch 47/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9654 - accuracy: 0.6421\n",
      "Epoch 00047: val_loss did not improve from 1.05790\n",
      "898/897 [==============================] - 21s 24ms/step - loss: 0.9654 - accuracy: 0.6421 - val_loss: 1.0776 - val_accuracy: 0.5974\n",
      "Epoch 48/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9535 - accuracy: 0.6443\n",
      "Epoch 00048: val_loss did not improve from 1.05790\n",
      "898/897 [==============================] - 23s 25ms/step - loss: 0.9545 - accuracy: 0.6440 - val_loss: 1.0776 - val_accuracy: 0.6066\n",
      "Epoch 49/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9537 - accuracy: 0.6463\n",
      "Epoch 00049: val_loss did not improve from 1.05790\n",
      "898/897 [==============================] - 27s 30ms/step - loss: 0.9536 - accuracy: 0.6463 - val_loss: 1.1131 - val_accuracy: 0.5996\n",
      "Epoch 50/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9482 - accuracy: 0.6490\n",
      "Epoch 00050: val_loss did not improve from 1.05790\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.9482 - accuracy: 0.6490 - val_loss: 1.0882 - val_accuracy: 0.6057\n",
      "Epoch 51/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9565 - accuracy: 0.6461\n",
      "Epoch 00051: val_loss did not improve from 1.05790\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9567 - accuracy: 0.6460 - val_loss: 1.0698 - val_accuracy: 0.6202\n",
      "Epoch 52/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9480 - accuracy: 0.6476\n",
      "Epoch 00052: val_loss did not improve from 1.05790\n",
      "898/897 [==============================] - 26s 29ms/step - loss: 0.9480 - accuracy: 0.6476 - val_loss: 1.0750 - val_accuracy: 0.6077\n",
      "Epoch 53/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9396 - accuracy: 0.6503\n",
      "Epoch 00053: val_loss did not improve from 1.05790\n",
      "898/897 [==============================] - 24s 26ms/step - loss: 0.9397 - accuracy: 0.6504 - val_loss: 1.0814 - val_accuracy: 0.6096\n",
      "Epoch 54/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9460 - accuracy: 0.6488\n",
      "Epoch 00054: val_loss did not improve from 1.05790\n",
      "898/897 [==============================] - 23s 25ms/step - loss: 0.9461 - accuracy: 0.6489 - val_loss: 1.1051 - val_accuracy: 0.6121\n",
      "Epoch 55/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9433 - accuracy: 0.6501\n",
      "Epoch 00055: val_loss did not improve from 1.05790\n",
      "898/897 [==============================] - 28s 31ms/step - loss: 0.9433 - accuracy: 0.6501 - val_loss: 1.1216 - val_accuracy: 0.6030\n",
      "Epoch 56/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9413 - accuracy: 0.6534\n",
      "Epoch 00056: val_loss did not improve from 1.05790\n",
      "898/897 [==============================] - 24s 26ms/step - loss: 0.9414 - accuracy: 0.6533 - val_loss: 1.1324 - val_accuracy: 0.5784\n",
      "Epoch 57/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9386 - accuracy: 0.6512\n",
      "Epoch 00057: val_loss improved from 1.05790 to 1.04358, saving model to models/_mini_XCEPTION.57-accuracy0.65.hdf5\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.9386 - accuracy: 0.6512 - val_loss: 1.0436 - val_accuracy: 0.6160\n",
      "Epoch 58/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9355 - accuracy: 0.6521\n",
      "Epoch 00058: val_loss did not improve from 1.04358\n",
      "898/897 [==============================] - 23s 25ms/step - loss: 0.9356 - accuracy: 0.6521 - val_loss: 1.0672 - val_accuracy: 0.6219\n",
      "Epoch 59/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9354 - accuracy: 0.6547\n",
      "Epoch 00059: val_loss did not improve from 1.04358\n",
      "898/897 [==============================] - 21s 24ms/step - loss: 0.9354 - accuracy: 0.6547 - val_loss: 1.1713 - val_accuracy: 0.5882\n",
      "Epoch 60/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9325 - accuracy: 0.6517\n",
      "Epoch 00060: val_loss did not improve from 1.04358\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.9327 - accuracy: 0.6516 - val_loss: 1.0746 - val_accuracy: 0.6183\n",
      "Epoch 61/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9316 - accuracy: 0.6539\n",
      "Epoch 00061: val_loss did not improve from 1.04358\n",
      "898/897 [==============================] - 28s 31ms/step - loss: 0.9315 - accuracy: 0.6540 - val_loss: 1.1372 - val_accuracy: 0.5971\n",
      "Epoch 62/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9322 - accuracy: 0.6530\n",
      "Epoch 00062: val_loss did not improve from 1.04358\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.9325 - accuracy: 0.6529 - val_loss: 1.0661 - val_accuracy: 0.6180\n",
      "Epoch 63/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9218 - accuracy: 0.6584\n",
      "Epoch 00063: val_loss did not improve from 1.04358\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9218 - accuracy: 0.6584 - val_loss: 1.1098 - val_accuracy: 0.6046\n",
      "Epoch 64/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9250 - accuracy: 0.6559\n",
      "Epoch 00064: val_loss did not improve from 1.04358\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9251 - accuracy: 0.6557 - val_loss: 1.1453 - val_accuracy: 0.5957\n",
      "Epoch 65/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9203 - accuracy: 0.6604\n",
      "Epoch 00065: val_loss did not improve from 1.04358\n",
      "898/897 [==============================] - 23s 25ms/step - loss: 0.9203 - accuracy: 0.6604 - val_loss: 1.1680 - val_accuracy: 0.5798\n",
      "Epoch 66/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9244 - accuracy: 0.6545\n",
      "Epoch 00066: val_loss did not improve from 1.04358\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9242 - accuracy: 0.6546 - val_loss: 1.0797 - val_accuracy: 0.6141\n",
      "Epoch 67/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9166 - accuracy: 0.6583\n",
      "Epoch 00067: val_loss did not improve from 1.04358\n",
      "898/897 [==============================] - 28s 31ms/step - loss: 0.9166 - accuracy: 0.6583 - val_loss: 1.0928 - val_accuracy: 0.6088\n",
      "Epoch 68/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9171 - accuracy: 0.6567\n",
      "Epoch 00068: val_loss did not improve from 1.04358\n",
      "898/897 [==============================] - 23s 26ms/step - loss: 0.9171 - accuracy: 0.6567 - val_loss: 1.0807 - val_accuracy: 0.6194\n",
      "Epoch 69/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9200 - accuracy: 0.6589\n",
      "Epoch 00069: val_loss improved from 1.04358 to 1.03545, saving model to models/_mini_XCEPTION.69-accuracy0.66.hdf5\n",
      "898/897 [==============================] - 21s 24ms/step - loss: 0.9200 - accuracy: 0.6589 - val_loss: 1.0354 - val_accuracy: 0.6358\n",
      "Epoch 70/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9106 - accuracy: 0.6630\n",
      "Epoch 00070: val_loss did not improve from 1.03545\n",
      "898/897 [==============================] - 21s 24ms/step - loss: 0.9108 - accuracy: 0.6631 - val_loss: 1.0954 - val_accuracy: 0.6052\n",
      "Epoch 71/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9175 - accuracy: 0.6577\n",
      "Epoch 00071: val_loss did not improve from 1.03545\n",
      "898/897 [==============================] - 24s 26ms/step - loss: 0.9177 - accuracy: 0.6577 - val_loss: 1.3333 - val_accuracy: 0.5472\n",
      "Epoch 72/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9127 - accuracy: 0.6625\n",
      "Epoch 00072: val_loss did not improve from 1.03545\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.9124 - accuracy: 0.6626 - val_loss: 1.0731 - val_accuracy: 0.6138\n",
      "Epoch 73/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9078 - accuracy: 0.6636\n",
      "Epoch 00073: val_loss did not improve from 1.03545\n",
      "898/897 [==============================] - 30s 33ms/step - loss: 0.9075 - accuracy: 0.6638 - val_loss: 1.1267 - val_accuracy: 0.6041\n",
      "Epoch 74/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9008 - accuracy: 0.6691\n",
      "Epoch 00074: val_loss did not improve from 1.03545\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.9008 - accuracy: 0.6691 - val_loss: 1.0393 - val_accuracy: 0.6286\n",
      "Epoch 75/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9059 - accuracy: 0.6645\n",
      "Epoch 00075: val_loss did not improve from 1.03545\n",
      "898/897 [==============================] - 23s 26ms/step - loss: 0.9060 - accuracy: 0.6645 - val_loss: 1.0998 - val_accuracy: 0.6038\n",
      "Epoch 76/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.9041 - accuracy: 0.6640\n",
      "Epoch 00076: val_loss did not improve from 1.03545\n",
      "898/897 [==============================] - 24s 27ms/step - loss: 0.9044 - accuracy: 0.6641 - val_loss: 1.1024 - val_accuracy: 0.6074\n",
      "Epoch 77/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9048 - accuracy: 0.6625\n",
      "Epoch 00077: val_loss did not improve from 1.03545\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.9050 - accuracy: 0.6624 - val_loss: 1.1820 - val_accuracy: 0.5899\n",
      "Epoch 78/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.9003 - accuracy: 0.6644\n",
      "Epoch 00078: val_loss did not improve from 1.03545\n",
      "898/897 [==============================] - 23s 26ms/step - loss: 0.9001 - accuracy: 0.6644 - val_loss: 1.0539 - val_accuracy: 0.6177\n",
      "Epoch 79/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.9039 - accuracy: 0.6623\n",
      "Epoch 00079: val_loss did not improve from 1.03545\n",
      "898/897 [==============================] - 30s 34ms/step - loss: 0.9039 - accuracy: 0.6623 - val_loss: 1.1263 - val_accuracy: 0.6060\n",
      "Epoch 80/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.8998 - accuracy: 0.6679\n",
      "Epoch 00080: val_loss did not improve from 1.03545\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.8997 - accuracy: 0.6679 - val_loss: 1.0690 - val_accuracy: 0.6197\n",
      "Epoch 81/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.8916 - accuracy: 0.6695\n",
      "Epoch 00081: val_loss did not improve from 1.03545\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "898/897 [==============================] - 23s 26ms/step - loss: 0.8916 - accuracy: 0.6695 - val_loss: 1.0568 - val_accuracy: 0.6250\n",
      "Epoch 82/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.8486 - accuracy: 0.6887\n",
      "Epoch 00082: val_loss improved from 1.03545 to 1.02885, saving model to models/_mini_XCEPTION.82-accuracy0.69.hdf5\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.8486 - accuracy: 0.6887 - val_loss: 1.0289 - val_accuracy: 0.6344\n",
      "Epoch 83/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.8397 - accuracy: 0.6903\n",
      "Epoch 00083: val_loss improved from 1.02885 to 1.02760, saving model to models/_mini_XCEPTION.83-accuracy0.69.hdf5\n",
      "898/897 [==============================] - 23s 26ms/step - loss: 0.8396 - accuracy: 0.6903 - val_loss: 1.0276 - val_accuracy: 0.6328\n",
      "Epoch 84/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.8319 - accuracy: 0.6942\n",
      "Epoch 00084: val_loss improved from 1.02760 to 1.01590, saving model to models/_mini_XCEPTION.84-accuracy0.69.hdf5\n",
      "898/897 [==============================] - 23s 26ms/step - loss: 0.8319 - accuracy: 0.6942 - val_loss: 1.0159 - val_accuracy: 0.6439\n",
      "Epoch 85/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.8297 - accuracy: 0.6922\n",
      "Epoch 00085: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 31s 34ms/step - loss: 0.8299 - accuracy: 0.6922 - val_loss: 1.0225 - val_accuracy: 0.6434\n",
      "Epoch 86/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.8209 - accuracy: 0.6983\n",
      "Epoch 00086: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 23s 25ms/step - loss: 0.8209 - accuracy: 0.6982 - val_loss: 1.0261 - val_accuracy: 0.6434\n",
      "Epoch 87/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.8185 - accuracy: 0.6952\n",
      "Epoch 00087: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.8185 - accuracy: 0.6952 - val_loss: 1.0236 - val_accuracy: 0.6431\n",
      "Epoch 88/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.8203 - accuracy: 0.6980\n",
      "Epoch 00088: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 24s 27ms/step - loss: 0.8203 - accuracy: 0.6980 - val_loss: 1.0265 - val_accuracy: 0.6417\n",
      "Epoch 89/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.8188 - accuracy: 0.6961\n",
      "Epoch 00089: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.8188 - accuracy: 0.6961 - val_loss: 1.0210 - val_accuracy: 0.6406\n",
      "Epoch 90/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.8140 - accuracy: 0.6985\n",
      "Epoch 00090: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 23s 26ms/step - loss: 0.8140 - accuracy: 0.6985 - val_loss: 1.0202 - val_accuracy: 0.6431\n",
      "Epoch 91/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.8187 - accuracy: 0.6970\n",
      "Epoch 00091: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 31s 35ms/step - loss: 0.8187 - accuracy: 0.6970 - val_loss: 1.0355 - val_accuracy: 0.6358\n",
      "Epoch 92/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.8141 - accuracy: 0.6979\n",
      "Epoch 00092: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.8142 - accuracy: 0.6979 - val_loss: 1.0211 - val_accuracy: 0.6431\n",
      "Epoch 93/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.8124 - accuracy: 0.6988\n",
      "Epoch 00093: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 23s 26ms/step - loss: 0.8124 - accuracy: 0.6988 - val_loss: 1.0230 - val_accuracy: 0.6434\n",
      "Epoch 94/100\n",
      "897/897 [============================>.] - ETA: 0s - loss: 0.8128 - accuracy: 0.7004\n",
      "Epoch 00094: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 23s 25ms/step - loss: 0.8127 - accuracy: 0.7004 - val_loss: 1.0298 - val_accuracy: 0.6400\n",
      "Epoch 95/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.8121 - accuracy: 0.7012\n",
      "Epoch 00095: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.8121 - accuracy: 0.7012 - val_loss: 1.0251 - val_accuracy: 0.6428\n",
      "Epoch 96/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.8096 - accuracy: 0.6992\n",
      "Epoch 00096: val_loss did not improve from 1.01590\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "898/897 [==============================] - 25s 27ms/step - loss: 0.8096 - accuracy: 0.6992 - val_loss: 1.0287 - val_accuracy: 0.6408\n",
      "Epoch 97/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.8007 - accuracy: 0.7021\n",
      "Epoch 00097: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 31s 34ms/step - loss: 0.8007 - accuracy: 0.7021 - val_loss: 1.0250 - val_accuracy: 0.6431\n",
      "Epoch 98/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.8019 - accuracy: 0.7053\n",
      "Epoch 00098: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 24s 26ms/step - loss: 0.8019 - accuracy: 0.7052 - val_loss: 1.0248 - val_accuracy: 0.6447\n",
      "Epoch 99/100\n",
      "896/897 [============================>.] - ETA: 0s - loss: 0.8008 - accuracy: 0.7014\n",
      "Epoch 00099: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 22s 25ms/step - loss: 0.8009 - accuracy: 0.7013 - val_loss: 1.0252 - val_accuracy: 0.6425\n",
      "Epoch 100/100\n",
      "898/897 [==============================] - ETA: 0s - loss: 0.8033 - accuracy: 0.7007\n",
      "Epoch 00100: val_loss did not improve from 1.01590\n",
      "898/897 [==============================] - 23s 26ms/step - loss: 0.8033 - accuracy: 0.7007 - val_loss: 1.0231 - val_accuracy: 0.6459\n"
     ]
    }
   ],
   "source": [
    "num_epochs=100\n",
    "input_shape=(48,48,1)\n",
    "verbose = 1\n",
    "num_classes=7\n",
    "patience = 50\n",
    "base_path = 'models/'\n",
    "model = mini_XCEPTION(input_shape,num_classes)\n",
    "model.compile(optimizer='adam', # 优化器采用adam\n",
    "              loss='categorical_crossentropy', # 多分类的交叉熵损失函数\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "log_file_path = base_path + '_emotion_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss',patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                              patience=int(patience/4),\n",
    "                              verbose=1)\n",
    "#存放模型位置及命名\n",
    "trained_models_path = base_path + '_mini_XCEPTION'\n",
    "#模型的名字命名：.epoch+准确率.hdf5\n",
    "model_names = trained_models_path + '.{epoch:02d}-accuracy{accuracy:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names,\n",
    "                                   'val_loss', verbose=1,\n",
    "                                    save_best_only=True)\n",
    "#进行断点的恢复\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "result = model.fit_generator(train_gen,steps_per_epoch=len(face_train) / batch_size,\n",
    "                        epochs=num_epochs,\n",
    "                        verbose=1, callbacks=callbacks,\n",
    "                        validation_data=(face_val,emotion_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T08:12:05.482120Z",
     "iopub.status.busy": "2020-09-02T08:12:05.472414Z",
     "iopub.status.idle": "2020-09-02T08:12:05.864556Z",
     "shell.execute_reply": "2020-09-02T08:12:05.865200Z"
    },
    "papermill": {
     "duration": 13.693563,
     "end_time": "2020-09-02T08:12:05.865370",
     "exception": false,
     "start_time": "2020-09-02T08:11:52.171807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#迭代了100个epoch,仅得到了0.68的准确率\n",
    "import matplotlib.pyplot as plt\n",
    "acc = result.history['accuracy'] #得到训练过程中的准确率和损失\n",
    "loss = result.history['loss']\n",
    "validation_acc = result.history['val_accuracy'] #验证集的准确率和损失\n",
    "validation_loss = result.history['val_loss']\n",
    "\n",
    "x = range(1,len(acc)+1)\n",
    "\n",
    "plt.plot(x,acc,'x-b',label = 'Training Accuracy')\n",
    "plt.plot(x,validation_acc,'o-m',label = 'Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(x,loss,'x-b',label = 'Training Loss')\n",
    "plt.plot(x,validation_loss,'o-m',label = 'Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 2395.463733,
   "end_time": "2020-09-02T08:12:20.348887",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-02T07:32:24.885154",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
